---
title: "Projeto Final"
format: html
warning: false
message: false
---

Tirar o boxplot e trocar por jitter + errobar (desvio padrão) --\> poucas repetições Anova só com o grupo significativo (só tratamentou ou dose, trabalhar só com um fator) Dose usar como repetições por exemplo Sem regressão --\> considerar como categorico, não continuo Transformar log para a dose (por ser exponencial) Talvez montar apresentação Powwerpoint --\> Muitos dados

# Pacotes utilizados

Antes de dar o início ao nosso projeto, segue a lista abaixo de todos os pacotes que foram carregados previamente e utilizados durante a nossa análise de dados.

```{r}
library(tidyverse)
library(readxl)
library(gsheet)
library(DT)
library(performance)
library(DHARMa)
library(multcomp)
library(multcompView)
library(emmeans)
library(MASS)
library(AgroR)
library(drc)
library(corrplot)
```

# Importação e Visualização do conjunto de dados

O primeiro passo para qualquer análise de dados é a importação dos dados que serão trabalhados. O nosso conjunto de dados foi importado por meio de um arquivo Excel (.xlsx) através da função `read_excel()` do pacote `readxl`. O nome atribuído ao data frame foi `controle`.

```{r}
controle <- read_excel("Controle biológico.xlsx")

controle
```

# Análise exploratória (visualização dos dados)

## Gráficos Boxplot usando "Dose" como fator e agrupando "Tratamento" por meio do `facet_wrap()`

```{r}
#Massa da parte aérea seca (MPAS)
controle |> 
  ggplot(aes(factor(Dose), `MPAS`, color = factor(Dose)))+
  geom_boxplot()+
  facet_wrap(~Trat)

#Massa da raiz fresca (MRF)
controle |> 
  ggplot(aes(factor(Dose), `MRF`, color = factor(Dose)))+
  geom_boxplot()+
  facet_wrap(~Trat)

#Número de ovos (ovos)
controle |> 
  ggplot(aes(factor(Dose), ovos, color = factor(Dose)))+
  geom_boxplot()+
  facet_wrap(~Trat)

#Ovos/g (ovosg)
controle |> 
  ggplot(aes(factor(Dose), `ovosg`, color = factor(Dose)))+
  geom_boxplot()+
  facet_wrap(~Trat)
```

## Gráficos Boxplot usando "Tratamento" como fator e agrupando "Dose" por meio do `facet_wrap()`

```{r}
#Massa da parte aérea seca (MPAS)
controle |> 
  ggplot(aes(Trat, `MPAS`, color = factor(Trat)))+
  geom_boxplot()+
  facet_wrap(~Dose)

#Massa da raiz fresca (MRF)
controle |> 
  ggplot(aes(Trat, `MRF`, color = factor(Trat)))+
  geom_boxplot()+
  facet_wrap(~Dose)

#Número de ovos (ovos)
controle |> 
  ggplot(aes(Trat, ovos, color = factor(Trat)))+
  geom_boxplot()+
  facet_wrap(~Dose)

#Ovos/g (ovosg)
controle |> 
  ggplot(aes(Trat, `ovosg`, color = factor(Trat)))+
  geom_boxplot()+
  facet_wrap(~Dose)
```

# Modelo fatorial (2-way ANOVA)

##Análise de variância da variável "Massa da parte aérea seca" (MPAS)

```{r}
mf <- lm(MPAS ~ Trat*factor(Dose),
         data = controle)
mf

anova(mf)
summary(mf)

#Checando as premissas
plot(simulateResiduals(mf)) 
check_normality(mf) #Não possui distribuição normal, no entanto podemos considerar como normal devido ao p-valor ser muito próximo do nível de significância (p = 0.045). Além disso a normalidade é menos importante que a homogeneidade das variâncias
check_heteroscedasticity(mf)

#Agrupamento dos dados em função da "Dose"
mf_mpas <- emmeans(mf, ~ Trat|Dose)
mf_mpas
cld(mf_mpas)
plot(cld(mf_mpas))

#Agrupamento dos dados em função do "Tratamento"
mf_mpas2 <- emmeans(mf, ~Dose|Trat)
cld(mf_mpas2)
plot(cld(mf_mpas2))
#Não deu nenhuma diferença estatisticamente significativa entre as diferentes doses, não precisa fazer regressão
```

##Análise de variância da variável "Massa da raiz fresca" (MRF)

```{r}
mf2 <- lm(MRF ~ Trat*factor(Dose),
         data = controle)
mf2

anova(mf2)
summary(mf2)

#Checando as premissas
plot(simulateResiduals(mf2)) 
check_normality(mf2)
check_heteroscedasticity(mf2)

#Agrupamento dos dados em função da "Dose"
mf_mrf <- emmeans(mf2, ~ Trat|Dose)
mf_mrf
cld(mf_mrf)
plot(cld(mf_mrf))

#Agrupamento dos dados em função do "Tratamento"
mf_mrf2 <- emmeans(mf2, ~Dose|Trat)
cld(mf_mrf2)
plot(cld(mf_mrf2))
#Tratamento D apresentou diferença significativa, parece formar uma parabola --> Fazer regressão??
```

##Análise de variância da variável "Número de ovos" (ovos)

```{r}
mf3 <- lm(ovos ~ Trat*factor(Dose),
         data = controle)
mf3

anova(mf3)
summary(mf3)

#Checando as premissas
plot(simulateResiduals(mf3)) 
check_normality(mf3)
check_heteroscedasticity(mf3) # Variâncias heterogêneas

#Transformação por Box-Cox
b <- boxcox(lm(controle$ovos+0.1 ~ 1)) #A partir do "b" iremos extrair o lambda
lambda <- b$x[which.max(b$y)]
lambda #O valor lambda será usado na transformação

controle$ovos2 <- (controle$ovos ^ lambda - 1)/ lambda
controle$ovos2 #Depois de transformado, é feito os mesmos testes

mf3.1 <- lm(ovos2 ~ Trat*factor(Dose),
         data = controle)
mf3.1

anova(mf3.1)
summary(mf3.1)

#Checando novamente as premissas após transformação
plot(simulateResiduals(mf3.1)) 
check_normality(mf3.1)
check_heteroscedasticity(mf3.1) #Variância homogênea

controle <- controle |> 
  mutate(ovos2 = (ovos^lambda - 1)/ lambda)

#Agrupamento dos dados em função da "Dose"
mf_ovos <- emmeans(mf3.1, ~ Trat|Dose)
mf_ovos
cld(mf_ovos)
plot(cld(mf_ovos))

#Agrupamento dos dados em função do "Tratamento"
mf_ovos2 <- emmeans(mf3.1, ~Dose|Trat)
cld(mf_ovos2)
plot(cld(mf_ovos2))
#Diferença significativa apenas no Tratamento B --> Fazer regressão
```

##Análise de variância da variável "Ovos/g" (ovosg)

```{r}
mf4 <- lm(ovosg ~ Trat*factor(Dose),
         data = controle)
mf4

anova(mf4)
summary(mf4)

#Checando as premissas
plot(simulateResiduals(mf4)) 
check_normality(mf4)
check_heteroscedasticity(mf4) #Variância heterogênea

#Transformação por Box-Cox
b2 <- boxcox(lm(controle$ovosg+0.1 ~ 1))
lambda2 <- b2$x[which.max(b2$y)]
lambda2

controle$ovosg2 <- (controle$ovosg ^ lambda2 - 1)/ lambda2
controle$ovosg2

mf4.1 <- lm(ovosg2 ~ Trat*factor(Dose),
         data = controle)
mf4.1

anova(mf4.1)
summary(mf4.1)

#Checando novamente as premissas após transformação
plot(simulateResiduals(mf4.1)) 
check_normality(mf4.1)
check_heteroscedasticity(mf4.1) #Variâncias homogêneas

#Agrupamento dos dados em função da "Dose"
mf_ovosg <- emmeans(mf4.1, ~ Trat|Dose)
mf_ovosg
cld(mf_ovosg)
plot(cld(mf_ovosg))

#Agrupamento dos dados em função do "Tratamento"
mf_ovosg2 <- emmeans(mf4.1, ~Dose|Trat)
cld(mf_ovosg2)
plot(cld(mf_ovosg2))
#Diferença significativa apenas para Tratamento B
```

# Regressão

## Regressão da variável "ovos" em função da "Dose"

```{r}
controle |> 
  ggplot(aes(Dose, ovos2))+
  geom_jitter(width = 0.1, color = "gray")+
  facet_wrap(~Trat)+
  stat_summary(fun.data = "mean_cl_boot", color = "blue")+
  geom_smooth(method = "lm", se = F) #se = F tira a banda de confiança

controle |> 
  ggplot(aes(Dose, ovos2))+
  geom_jitter(width = 0.1, color = "gray")+
  facet_wrap(~Trat)+
  stat_summary(fun.data = "mean_cl_boot", color = "blue")+
  geom_smooth(se = F)
```

##Tratamento A

```{r}
trat1 <- controle |> 
  filter(Trat == "A")

#Gráfico sem ajustar modelo
trat1 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(se = F)

#Gráfico ajustando modelo linear e quadrático
trat1 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(method = lm, se = FALSE,
              formula = y ~poly(x,2))+ #Formula par ajustar os dados, modelo quadrático
  geom_smooth(method = lm, se = F, color = "red") #Modelo linear

#Gráfico ajustando modelo cúbico
trat1 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(method = lm, se = FALSE,
              formula = y ~poly(x,3)) #Formula par ajustar os dados, modelo cúbico

trat1$Dose2 <- trat1$Dose^2
trat1$Dose3 <- trat1$Dose^3

#Primeira ordem - modelo linear
lm1 <- lm(ovos2 ~ Dose,
          data = trat1)
summary(lm1)

#Segunda ordem ou quadrático - modelo quadrático
lm1.2 <- lm(ovos2 ~ Dose + Dose2,
          data = trat1)
summary(lm1.2) 

#Terceira ordem - modelo cúbico
lm1.3 <- lm(ovos2 ~ Dose + Dose2 + Dose3,
          data = trat1)
summary(lm1.3)

#COmparação dos 3 modelos (menor valor = melhor modelo)
AIC(lm1) #Menor valor
AIC(lm1.2) 
AIC(lm1.3)

#Gráfico dos modelos com o valor de R-quadrado
with(trat1, polynomial(Dose, ovos2, grau = 1))
with(trat1, polynomial(Dose, ovos2, grau = 2)) #diferente do AIC, deu maior que o linear
with(trat1, polynomial(Dose, ovos2, grau = 3)) #R2 = 1, teoricamente melhor, mas superestima o número de ovos


#Testando modelo não-linear  --> NÃO DEU CERTO
drc1 <- drm(ovos2 ~ Dose, data = trat1,  #drm é uma função que ajusta modelo não-linear
            fct = LL.3()) #LL.3 = log-logistic de 3 parâmetros
AIC(drc1) #Para comparar diferentes modelos (fct), o W1.3 pode ser melhor para alguns isolados
plot(drc1) #Para visualizar se o ajuste está bom
ED(drc1, 50, interval = "delta") #Estima o EC50 no valor 0.55 | O interval = delta fornece o intervalod de confiança

drc1.1 <- drm(ovos2 ~ Dose, data = trat1,  #drm é uma função que ajusta modelo não-linear
            fct = W1.3()) #LL.3 = log-logistic de 3 parâmetros
AIC(drc1.1) #Para comparar diferentes modelos (fct), o W1.3 pode ser melhor para alguns isolados
plot(drc1.1)
```

## Tratamento B

```{r}
trat2 <- controle |> 
  filter(Trat == "B")

#Gráfico sem ajustar modelo
trat2 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(se = F)

#Gráfico ajustando modelo linear e quadrático
trat2 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(method = lm, se = FALSE,
              formula = y ~poly(x,2))+
  geom_smooth(method = lm, se = F, color = "red")

#Gráfico ajustando modelo cúbico
trat2 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(method = lm, se = FALSE,
              formula = y ~poly(x,3))

trat2$Dose2 <- trat2$Dose^2
trat2$Dose3 <- trat2$Dose^3

#Primeira ordem
lm2 <- lm(ovos2 ~ Dose,
          data = trat2)
summary(lm2)

#Segunda ordem ou quadrático
lm2.2 <- lm(ovos2 ~ Dose + Dose2,
          data = trat2)
summary(lm2.2)

#Terceira ordem
lm2.3 <- lm(ovos2 ~ Dose + Dose2 + Dose3,
          data = trat2)
summary(lm2.3)

#Comparação dos 3 modelos
AIC(lm2)
AIC(lm2.2) 
AIC(lm2.3)#DEU O MENOR VALOR

plot(simulateResiduals(lm2.3))
check_normality(lm2.3)
check_heteroscedasticity(lm2.3)

#Gráfico dos modelos com o valor de R-quadrado
with(trat2, polynomial(Dose, ovos2, grau = 2))
with(trat2, polynomial(Dose, ovos2, grau = 3))

#Testando modelo não-linear --> NÃO DEU CERTO
drc2 <- drm(ovos2 ~ Dose, data = trat2,
            fct = LL.3())
AIC(drc2)
plot(drc2)
ED(drc2, 50, interval = "delta")

drc2.1 <- drm(ovos2 ~ Dose, data = trat2,  #drm é uma função que ajusta modelo não-linear
            fct = W1.3()) #LL.3 = log-logistic de 3 parâmetros
AIC(drc2.1) #Para comparar diferentes modelos (fct), o W1.3 pode ser melhor para alguns isolados
plot(drc2.1)
```

## Tratamento C

```{r}
trat3 <- controle |> 
  filter(Trat == "C")

#Gráfico sem ajustar modelo
trat3 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(se = F)

#Gráfico ajustando modelo linear e quadrático
trat3 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(method = lm, se = FALSE,
              formula = y ~poly(x,2))+ 
  geom_smooth(method = lm, se = F, color = "red")

#Gráfico ajustando modelo cúbico
trat3 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(method = lm, se = FALSE,
              formula = y ~poly(x,3))

trat3$Dose2 <- trat3$Dose^2
trat3$Dose3 <- trat3$Dose^3

#Primeira ordem
lm3 <- lm(ovos2 ~ Dose,
          data = trat3)
summary(lm3)

#Segunda ordem ou quadrático
lm3.2 <- lm(ovos2 ~ Dose + Dose2,
          data = trat3)
summary(lm3.2)

#Terceira ordem
lm3.3 <- lm(ovos2 ~ Dose + Dose2 + Dose3,
          data = trat1)
summary(lm3.3)

#Comparando 3 modelos
AIC(lm3) #Menor valor
AIC(lm3.2) 
AIC(lm3.3)

#Gráfico dos modelos com o valor de R-quadrado
with(trat3, polynomial(Dose, ovos2, grau = 1))
with(trat3, polynomial(Dose, ovos2, grau = 2)) #diferente do AIC, deu maior que o linear
with(trat3, polynomial(Dose, ovos2, grau = 3)) #R2 = 1, teoricamente melhor, mas superestima o número de ovos


#Testando modelo não-linear  --> NÃO DEU CERTO
drc3 <- drm(ovos2 ~ Dose, data = trat3,  #drm é uma função que ajusta modelo não-linear
            fct = LL.3()) #LL.3 = log-logistic de 3 parâmetros
AIC(drc3) #Para comparar diferentes modelos (fct), o W1.3 pode ser melhor para alguns isolados
plot(drc3) #Para visualizar se o ajuste está bom
ED(drc3, 50, interval = "delta") #Estima o EC50 no valor 0.55 | O interval = delta fornece o intervalod de confiança

drc3.1 <- drm(ovos2 ~ Dose, data = trat3,  #drm é uma função que ajusta modelo não-linear
            fct = W1.3()) #LL.3 = log-logistic de 3 parâmetros
AIC(drc3.1) #Para comparar diferentes modelos (fct), o W1.3 pode ser melhor para alguns isolados
plot(drc3.1)

```

## Tratamento D

```{r}
trat4 <- controle |> 
  filter(Trat == "D")

#Gráfico sem ajustar modelo
trat4 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(se = F)

#Gráfico ajustando modelo linear e quadrático
trat4 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(method = lm, se = FALSE,
              formula = y ~poly(x,2))+ 
  geom_smooth(method = lm, se = F, color = "red")

#Gráfico ajustando modelo cúbico
trat4 |> 
  ggplot(aes(Dose, ovos2))+
  geom_point()+
  geom_smooth(method = lm, se = FALSE,
              formula = y ~poly(x,3))

trat4$Dose2 <- trat4$Dose^2
trat4$Dose3 <- trat4$Dose^3

#Primeira ordem
lm4 <- lm(ovos2 ~ Dose,
          data = trat4)
summary(lm4)

#Segunda ordem ou quadrático
lm4.2 <- lm(ovos2 ~ Dose + Dose2,
          data = trat4)
summary(lm4.2)

#Terceira ordem
lm4.3 <- lm(ovos2 ~ Dose + Dose2 + Dose3,
          data = trat4)
summary(lm4.3)

#Comparando 3 modelos
AIC(lm4) #Menor valor
AIC(lm4.2) 
AIC(lm4.3)

#Gráfico dos modelos com o valor de R-quadrado
with(trat4, polynomial(Dose, ovos2, grau = 1))
with(trat4, polynomial(Dose, ovos2, grau = 2)) #diferente do AIC, deu maior que o linear (muito baixo)
with(trat4, polynomial(Dose, ovos2, grau = 3)) #R2 = 1, teoricamente melhor, mas superestima o número de ovos


#Testando modelo não-linear  --> NÃO DEU CERTO
drc4 <- drm(ovos2 ~ Dose, data = trat4,  #drm é uma função que ajusta modelo não-linear
            fct = LL.3()) #LL.3 = log-logistic de 3 parâmetros
AIC(drc4) #Para comparar diferentes modelos (fct), o W1.3 pode ser melhor para alguns isolados
plot(drc4) #Para visualizar se o ajuste está bom
ED(drc4, 50, interval = "delta") #Estima o EC50 no valor 0.55 | O interval = delta fornece o intervalod de confiança

drc4.1 <- drm(ovos2 ~ Dose, data = trat4,  #drm é uma função que ajusta modelo não-linear
            fct = W1.3()) #LL.3 = log-logistic de 3 parâmetros
AIC(drc4.1) #Para comparar diferentes modelos (fct), o W1.3 pode ser melhor para alguns isolados
plot(drc4.1)
```

# Análise de Correlação

Como foram obtidas três variáveis respostas a partir do experimento base, além da variável resposta de ovos/g, e estas variáveis foram analisadas separadamente, foi realizado uma análise para avaliar se essas variáveis estão correlacionadas, ou seja, se existe alguma associação entre elas. Por meio da análise de correlação, testou-se a seguinte hipótese:

-   Hipótese nula (H0): não há correlação significativa entre as duas variáveis analisadas.

-   Hipótese alternativa (Ha): há uma correlação significativa entre as duas variáveis analisadas.


## Correlação entre Ovos e Massa de Parte Aérea Seca (MPAS)

**Visualização gráfica da correlação**: O primeiro passo para analisar a correlação entre duas variáveis quantitativas deve ser a visualização do gráfico de dispersão, a fim de identificar se existe uma variabilidade gradual entre os conjuntos de dados, se essa variação é monotônica (predominantemente ascendente ou descendente) e se assume uma tendência proporcional (linear).

A visualização gráfica foi montada com um `ggplot()` usando as funções `geom_point()` e `geom_smooth()`.

```{r}
controle |> 
  ggplot(aes(ovos, MPAS))+
  geom_point()+
  geom_smooth(method = "lm")
```

Baseando apenas na análise visual do gráfico de dispersão, é possível inferir que existe uma correlação positiva entre as variáveis "Ovos" e "MPAS", tendo em vista que a linha de tendência criada pelo `geom_smooth()` tem um perfil ascendente.

**Teste de Correlação**: Para realizar o teste de correlação, usou-se a função `cor.test()`, que é parte do pacote base do R.

```{r}
cor.test(controle$ovos, controle$MPAS)
```

O p-valor da análise da relação entre as variáveis foi menor do que o nível de significância (0,05), indicando que a hipótese nula deve ser rejeitada. Além disso, a análise de correlação para as variáveis "Ovos" e "MPAS" obteve um coeficiente de correlação de Pearson estimado de 0.44, demonstrando que existe uma correlação fraca positiva entre as duas variáveis, lembrando que para correlação positiva o coeficiente de correlação (r) varia de 0 a 1.


## Correlação entre Ovos e Massa de Raiz Fresca (MRF)

**Visualização gráfica da correlação**: 

```{r}
controle |> 
  ggplot(aes(ovos, MRF))+
  geom_point()+
  geom_smooth(method = "lm")
```

Baseando apenas na análise visual do gráfico de dispersão, é possível inferir que existe uma correlação positiva entre as variáveis "Ovos" e "MRF", tendo em vista que a linha de tendência criada pelo `geom_smooth()` tem um perfil ascendente.

**Teste de Correlação**: 

```{r}
cor.test(controle$ovos, controle$MRF)
```

O p-valor da análise da relação entre as variáveis foi menor do que o nível de significância (0,05), indicando que a hipótese nula deve ser rejeitada. Além disso, a análise de correlação para as variáveis "Ovos" e "MRF" obteve um coeficiente de correlação de Pearson estimado de 0.49, sendo maior que a correlação entre "Ovos" e "MPAS", embora ainda seja considerado uma correlação fraca positiva entre as duas variáveis.


## Correlação entre Massa de Parte Aérea Seca (MPAS) e Massa de Raiz Fresca (MRF)

**Visualização gráfica da correlação**: 

```{r}
controle |> 
  ggplot(aes(MPAS, MRF))+
  geom_point()+
  geom_smooth(method = "lm")
```

Diferente dos outros dois gráficos, a primeira diferença que é possível de observar é a menor dispersão entre os dados das duas variáveis, o que normalmente indica uma correlação mais forte. Isso também é perceptível pela barra de erros nesse gráfico, sendo mais afunilado se comparado aos outros dois anteriores. Novamente a linha de tendência criada pelo `geom_smooth()` tem um perfil ascendente.

**Teste de Correlação**: 

```{r}
cor.test(controle$MPAS, controle$MRF)
```

Novamente o p-valor da análise da relação entre as variáveis foi menor do que o nível de significância (0,05), indicando que a hipótese nula deve ser rejeitada. Nessa análise de correlação, podemos observar que as variáveis "MPAS" e "MRF" obtiveram um coeficiente de correlação de Pearson estimado de 0.72, bem maior que os coeficientes vistos na duas correlações anteriores, demonstrando que existe uma correlação positiva mais forte entre essas duas variáveis.

Essa correlação mais forte entre as variáveis "MPAS" e "MRF" era, na verdade, já esperado por nós, uma vez que biologicamente existe uma correlação forte entre a massa da raiz e a massa da parte aérea, ou seja, já é esperado que uma planta que possua maior biomassa de raiz tenha uma maior biomassa da parte aérea.


## Correlação entre todas as variáveis

É possível visualizar a correlação entre todas as variáveis resposta através de um único gráfico a partir da função ´corgraph()` do pacote `AgroR`. 

Para isso, é preciso primeiro filtrar apenas os dados das variáveis resposta. A esse conjunto de dados filtrado foi atribuído o nome `controle2`.

```{r}
controle2 <- controle[, c("ovos", "MPAS", "MRF")]
corgraph(controle2)
```
